{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"colab":{"name":"2.3_exploratory_text_analysis.ipynb","provenance":[{"file_id":"1CZz9dEeFC4D9UjiSAy6RbntMJPOImYE5","timestamp":1637258850498},{"file_id":"1qXhcxHtjIoWxk1Q5qj3eMEEp0hB2OjdO","timestamp":1637258839537}],"collapsed_sections":["EG81OCqplJYO"]}},"cells":[{"cell_type":"markdown","metadata":{"id":"dQNiy9KS72Wu"},"source":["## Setup"]},{"cell_type":"code","metadata":{"id":"QbTjluH7AgiL"},"source":["!pip uninstall pandas-profiling"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q80IFPh63WAE"},"source":["#!pip install pandas-profiling\n","#!pip install --upgrade pandas-profiling\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AVEtblOQ-VS8"},"source":["import nltk\n","import spacy\n","import pandas as pd\n","import numpy as np\n","import pandas_profiling as prof\n","\n","from pathlib import Path\n","from textblob import TextBlob\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","%matplotlib inline\n","matplotlib.rcParams['figure.figsize'] = (10.0, 6.0)\n","import plotly.graph_objs as go\n","\n","import cufflinks as cf\n","import plotly.graph_objs as go\n","import plotly.figure_factory as ff\n","from plotly.offline import iplot\n","from IPython.core.interactiveshell import InteractiveShell\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","InteractiveShell.ast_node_interactivity = 'all'\n","cf.go_offline()\n","cf.set_config_file(offline=False, world_readable=True, theme='pearl')\n","\n","pd.options.display.max_colwidth = 100\n","pd.options.display.max_columns = 30\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yrx8ttbG9M9u"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_a8j5A8h-j2i"},"source":["## Exploratory Data Analysis (EDA)\n","\n","\n","You can do EDA using this simple method: Pandas Profiling\n","Generates profile reports from a pandas DataFrame. The pandas df.describe() function is great but a little basic for serious exploratory data analysis. pandas_profiling extends the pandas DataFrame with df.profile_report() for quick data analysis.\n","\n","For each column the following statistics - if relevant for the column type - are presented in an interactive HTML report:\n","\n","* Type inference: detect the types of columns in a dataframe.\n","* Essentials: type, unique values, missing values\n","* Quantile statistics like minimum value, Q1, median, Q3, maximum, range, interquartile range\n","* Descriptive statistics like mean, mode, standard deviation, sum, median absolute deviation, coefficient of variation, kurtosis, skewness\n","* Most frequent values\n","* Histogram\n","* Correlations highlighting of highly correlated variables, Spearman, Pearson and Kendall matrices\n","* Missing values matrix, count, heatmap and dendrogram of missing values\n","* Text analysis: learn about categories (Uppercase, Space), scripts (Latin, Cyrillic) and blocks (ASCII) of text data.\n","---\n","\n","\n","Play & Learn\n","\n","> Learn more about data profiling: https://github.com/pandas-profiling/pandas-profiling\n","> Dive into sentiment analysis with TextBlob: https://textblob.readthedocs.io/en/dev/"]},{"cell_type":"code","metadata":{"id":"bqXwlPpK9vlF"},"source":["# Load dataset\n","data_folder = Path(\"/content/drive/MyDrive/CLT/S2/data/\")\n","clothing_reviews = data_folder / \"Womens Clothing E-Commerce Reviews.csv\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EG81OCqplJYO"},"source":["### Manual EDA\n","with Pandas built-in methods\n","\n","Overview:\n","* DataFrame.count: Count number of non-NA/null observations.\n","* DataFrame.max: Maximum of the values in the object.\n","* DataFrame.min: Minimum of the values in the object.\n","* DataFrame.mean: Mean of the values.\n","* DataFrame.std: Standard deviation of the observations.\n","* DataFrame.select_dtypes: Subset of a DataFrame including/excluding           columns based on their dtype."]},{"cell_type":"code","metadata":{"id":"nuuprPbW-N4-"},"source":["# Inspect the data frame\n","df = pd.read_csv(clothing_reviews)\n","df.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UoIjfRCk_Uk2"},"source":["# Inspect the dimensionality of your DataFrame. The shape attribute of pandas.DataFrame stores the number of rows and columns as a tuple (number of rows, number of columns).\n","df.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ZQDjZNW2dxG"},"source":["# Remove unused coloumns\n","df.drop('Unnamed: 0', axis=1, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CfHN-nCrGwtm"},"source":["# Print information about your DataFrame. You can inspect the total memory usage, the data type of each column, and the number of non-NaN elements.\n","df.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OTZ9kTlBVLjK"},"source":["# Remove 'Title' feature <- many titles are missing\n","df.drop('Title', axis=1, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mWaYm3b9gea9"},"source":["# Remove 'Review Text' without text\n","df.dropna(subset=['Review Text'], inplace=True)\n","\n","# Remove rows with missing 'Department Name'\n","df.dropna(subset=['Department Name'], inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3VFETNnWV-yl"},"source":["# Clean up the 'Review Text' data a little\n","def preprocess(text):\n","    text = text.str.replace(\"(<br/>)\", \"\")\n","    text = text.str.replace('(<a).*(>).*(</a>)', '')\n","    text = text.str.replace('(&amp)', '')\n","    text = text.str.replace('(&gt)', '')\n","    text = text.str.replace('(&lt)', '')\n","    text = text.str.replace('(\\xa0)', ' ')  \n","    return text\n","\n","df['Review Text'] = preprocess(df['Review Text'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9UQ99o8xZB8R"},"source":["# We will add some basic text features to the data\n","\n","# Add 'Review lenght'\n","df['Review Length'] = df['Review Text'].astype(str).apply(len)\n","\n","# Add simple token count\n","df['Num Tokens'] = df['Review Text'].apply(lambda x: len(str(x).split()))\n","\n","# Add polarity\n","df['Polarity'] = df['Review Text'].map(lambda text: TextBlob(str(text)).sentiment.polarity)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LKBG0xtcZ8Tv"},"source":["We are using a simple sentiment library, `TextBlob` to calculate sentiment polarity which lies in the range of [-1,1] where **1 means positive** sentiment and **-1 means a negative** sentiment."]},{"cell_type":"code","metadata":{"id":"f_hcDEoUat-D"},"source":["# Sentiment examples\n","print (TextBlob('I love chocolate.').sentiment.polarity)\n","print (TextBlob('I hate chocolate.').sentiment.polarity)    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WoxeQwtTc2rF"},"source":["df.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AxhHzIql_fAU"},"source":["# Descriptive statistics of your dataframe\n","df.describe()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FDuKD1b2dNq7"},"source":["# Take a look at our new features\n","df.iloc[0][['Review Text', 'Review Length', 'Num Tokens']]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mq0ifBqLJPQt"},"source":["By default, if you only type your_dataframe.describe(), the describe method will compute summary statistics on all of the **numeric variables** in your dataframe.\n","\n","The include parameter enables you to specify what data types to operate on and include in the output descriptive statistics.\n","\n","Possible arguments to this parameter are:\n","\n","* 'all' (this will include all variables)\n","* numpy.number (this will include numeric variables)\n","* object (this will include string variables)\n","* 'category' (this will include Pandas category variables)\n","\n","![picture](https://drive.google.com/uc?id=1Achtqzn3MH8do0roqHNCoEU32v7uPK-1)"]},{"cell_type":"markdown","metadata":{"id":"0unA76rQqTML"},"source":["<img src=”https://cdn-images-1.medium.com/fit/c/75/75/1*6_fgYnisCa9V21mymySIvA.png” width=”100\">"]},{"cell_type":"code","metadata":{"id":"VBonQ7c2JZVZ"},"source":["df.describe(include = [np.number])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Klrg5-WKm8m"},"source":["Here, the syntax np.number indicates that we want to include numeric variables (i.e., Numpy numerics).\n","\n","**percentiles** = By default, pandas will include the 25th, 50th, and 75th percentile. However you can tell pandas whichever ones you want. Simply pass a list to percentiles and pandas will do the rest.\n","\n","**include** = You may want to ‘describe’ all of your columns, or you may just want to do the numeric columns. By default, pandas will only describe your numeric columns. Select ‘all’ to include all columns.\n","\n","**exclude** = The inverse of include, you can tell pandas which column data types you would like to exclude. Simply pass a list of datatypes you would like to exclude here.\n","\n","**datetime_is_numeric:** By default pandas will treat your datetimes as objects. Meaning, Pandas will not calculate things like ‘average time/date’. However, if you select datetime_is_numeric=True then pandas will apply the min, max, and percentiles to your datetimes."]},{"cell_type":"code","metadata":{"id":"hgY4nua__o8L"},"source":["# Let's compute the summary statistics for the string variables.\n","df.describe(include = [object])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6r6Apw7vLGr_"},"source":["We called the describe() method, and inside the parenthesis, we used the syntax include = [object]. Here, object refers to string variables, so the Pandas describe method computes summary stats for the string columns.\n","\n","Notice that the statistics that are computed are actually different than the stats for the numeric variables.\n","\n","For the numeric variables, describe() computes things like the minimum, maximum, mean, percentiles, etc.\n","\n","But for these string variables, describe() has computed the count, the number of unique values, the most frequent value, and the frequency of the most frequent value."]},{"cell_type":"markdown","metadata":{"id":"Zkv1ojexuwgU"},"source":["### Automated EDA\n","using Pandas Profiling library"]},{"cell_type":"code","metadata":{"id":"W7h9quqXLpv0"},"source":["# Let's boost data profiling to the next level and be lazy\n","profile = prof.ProfileReport(df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mnDQ6MedQLRQ"},"source":["profile.to_file(output_file= data_folder /'clothing_data_profile.html')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b7WFaxE3_VFB"},"source":["## Exploratory Text Analysis (ETA)\n","\n","Some of the text features' analysis were recently implemented in pandas profiling. However, a lot of them are still missing. Let's take a look at how to build them ourselves."]},{"cell_type":"code","metadata":{"id":"GUkx6LazT4tz"},"source":["# Let's start with some visuals\n","!pip install WordCloud"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xz31hBeWvmY9"},"source":["### Wordclouds\n","Word Cloud is a data visualization technique used for representing text data in which the size of each word indicates its frequency or importance. Significant textual data points can be highlighted using a word cloud. Word clouds are widely used for analyzing data from social network websites.\n","\n","---\n","\n","### Learn & play:\n","> If you want to go fancy: https://www.datacamp.com/community/tutorials/wordcloud-python"]},{"cell_type":"code","metadata":{"id":"nsOGLNEfURHE"},"source":["from wordcloud import WordCloud \n","import matplotlib.pyplot as plt \n","import seaborn as sns\n","\n","# Set preferences\n","sns.set(color_codes=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jRhkiH3OUVfx"},"source":["# Get all review texts\n","all_reviews = df['Review Text']\n","all_reviews[-1:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gjWy4nGsXVSh"},"source":["# Concatenate strings in the Series/Index with cat() function to have all reviews as a string.\n","all_reviews.str.cat()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qM66T9U_XD84"},"source":["# Now let's generate a wordcloud for some reviews\n","wordcloud = WordCloud(width = 500, height = 500, \n","                background_color ='white',\n","                min_font_size = 10).generate(all_reviews.str.cat())\n","  \n","# plot the WordCloud image                        \n","plt.figure(figsize = (6, 6), facecolor = None) \n","plt.imshow(wordcloud) \n","plt.axis(\"off\") \n","plt.tight_layout(pad = 0) \n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mWB8T6_wa8mi"},"source":["# What departments do we have in the dataset?\n","df['Department Name'].value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ZLTm1kwSFV1"},"source":["# Compare two departments\n","jackets = df[df['Department Name'] == 'Jackets']['Review Text']\n","intimate = df[df['Department Name'] == 'Intimate']['Review Text']\n","print(intimate.str.cat()[:100])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bzfahpr38rCv"},"source":["rows=1\n","cols=2\n","\n","row=0 \n","col=0\n","titles = ['Jackets', 'Intimate']\n","w = [jackets.str.cat(),intimate.str.cat(),]\n","fig, ax = plt.subplots(1, 2, figsize=(12.5,6.5))\n","\n","for i in range(2):\n","  ax[col].imshow(WordCloud(width = 500, height = 500, \n","                background_color ='white', \n","                min_font_size = 10).generate(w[i]))\n","  ax[col].axis(\"off\")\n","  ax[col].set_title(titles[i], fontdict={'fontsize': 15, 'fontweight' : 'bold'})\n","  row=row+1\n","  if row==rows:\n","     row=0\n","     col=col+1\n","\n","plt.subplots_adjust(left=0.07, right=0.93, wspace=0.1, hspace=0.0,top=0.94,bottom=0.09)\n","plt.show() "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3aOwffPMo59q"},"source":["# To make this code more scalable, we will automate the wordcloud generation for all categories next.\n","g = df.groupby(['Department Name'])['Review Text']\n","for i, k in g:\n","  i\n","  print(k.str.cat()[:100])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PC-RCj3OlFCn"},"source":["What can you notice about preprocessing in the above word clouds?"]},{"cell_type":"code","metadata":{"id":"VM_MKBqQlh1V"},"source":["# Word clouds for all departments\n","np.random.seed(1)\n","\n","figure, axes = plt.subplots(2, 3, figsize=(18, 14))\n","cluster_groups = list(i.str.cat() for k, i in df.groupby(['Department Name'])['Review Text'])\n","cluster_titles = list(k for k, i in df.groupby(['Department Name'])['Review Text'])\n","i = 0\n","for r in range(2):\n","    for c in range(3):\n","        df_cluster = cluster_groups[i]\n","        wordcloud_image = WordCloud(width = 500, height = 500, \n","                background_color ='white', \n","                min_font_size = 10).generate(df_cluster) \n","        ax = axes[r][c]\n","        ax.imshow(wordcloud_image,\n","                  interpolation=\"bilinear\")\n","        ax.set_title(cluster_titles[i], fontsize=20)\n","        ax.set_xticks([])\n","        ax.set_yticks([])\n","        i = i + 1\n","\n","plt.subplots_adjust(left=0.07, right=0.93, wspace=0.08, hspace=0.0,top=0.9,bottom=0.09)\n","#plt.tight_layout()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wZpSSoFX0kDz"},"source":["Now that we have some insights about the vocabulary of the reviews, let's dig deeper. We will inspect some of our features."]},{"cell_type":"markdown","metadata":{"id":"ARwCIWGo2dxI"},"source":["### Univariate analyses\n","Single-variable or univariate visualization is the simplest type of visualization which consists of observations on only a single characteristic or attribute. Univariate visualization includes histogram, bar plots and line charts."]},{"cell_type":"markdown","metadata":{"id":"5IVX6tMP3uG8"},"source":["#### Polarity\n","Inspect polarity distribution."]},{"cell_type":"code","metadata":{"id":"hsiQTj-C2dxH"},"source":["# Select some reviews with high sentiment polarity\n","high_pol = df.loc[df['Polarity'] == 1, ['Review Text']].sample(5).values\n","for r in high_pol:\n","  print(r[0] + '\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kysdjRx02dxI"},"source":["# Select some reviews with low sentiment polarity\n","low_pol = df.loc[df['Polarity'] < -0.5, ['Review Text']].sample(5).values\n","for r in low_pol:\n","    print(r[0]+ '\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zOOrDcLl2dxI"},"source":["df['Polarity'].min()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ocmACPN-2dxI"},"source":["df.loc[df['Polarity'] < -0.8]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UJmmNguY2dxI"},"source":["# Plot the distribution of polarity sentiment score\n","# change plotting colors per client request\n","plt.style.use('ggplot')\n","df['Polarity'].plot(kind='hist', bins=50)\n","plt.xlabel('Polarity')\n","plt.title('Polarity distribution')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DETfPwsl90ud"},"source":["#### Knowledge check 🤔  \n","\n","Why does hist makes sense here?"]},{"cell_type":"markdown","metadata":{"id":"YAMAy9Cn2dxI"},"source":["Vast majority of the polarity are greater than 0, means most of them are positive."]},{"cell_type":"markdown","metadata":{"id":"A_G1PaXz2dxJ"},"source":["#### Ratings"]},{"cell_type":"code","metadata":{"id":"HcXwQBU52dxJ"},"source":["df['Rating'].value_counts().sort_index().plot(kind='bar', color='cadetblue')\n","#colourmaps= 'summer'\n","plt.xlabel('Rating')\n","plt.title('Rating distribution')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tc4kganw2dxJ"},"source":["The ratings are in align with the polarity, that is, most of the ratings are at 4 or 5 range."]},{"cell_type":"markdown","metadata":{"id":"7OtY7aoZ2dxJ"},"source":["#### Age"]},{"cell_type":"code","metadata":{"id":"8KJ9Qss62dxJ"},"source":["df['Age'].plot(kind='hist', bins=20, color='peru')\n","#colourmaps= 'summer'\n","plt.xlabel('Age')\n","plt.title('Age distribution')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dyGJjVim2dxJ"},"source":["Most reviewers are in their 30s to 40s."]},{"cell_type":"markdown","metadata":{"id":"VdX8_K5-2dxJ"},"source":["### Multivariate analyses\n","\n","\n","\n","---\n","\n","\n","### Learn & play:\n","Always read the documentation!\n","\n","- [Pandas Plotting Documentation](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.plot.html)\n","\n","- [Matplotlib Documentation](https://matplotlib.org/)\n","\n","- [Matplotlib sample plots](https://matplotlib.org/tutorials/introductory/sample_plots.html)"]},{"cell_type":"code","metadata":{"id":"XXwcFtxPKDGX"},"source":["df.hist(figsize=(16,8));"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y3gYdQDaKUat"},"source":["#### Knowledge check  🤔  \n","\n","Why doesn't it make plots of ALL the columns in the dataframe?\n","Hint: what is different about the columns it plots vs. the ones it left out?"]},{"cell_type":"markdown","metadata":{"id":"iU08ySMYOLMu"},"source":["#### Scatter plot"]},{"cell_type":"code","metadata":{"id":"VzDdlfO-K0Pm"},"source":["#Scatter plots are very good at showing the **interaction between two numeric variables** (especially when they're continuous)!\n","df.plot(kind='scatter', x='Review Length', y='Polarity', \\\n","        color='plum', figsize=(10,4), s=10, alpha=0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FZ_y66_9L0VA"},"source":["#### Scatter matrix\n","We can also use a thing called a scatter matrix or a pairplot, which is a grid of scatter plots. This allows you to quickly view the interaction of N x M features. You are generally looking for a trend between variables (a line or curve). Using machine learning, you can fit these curves to provide predictive power."]},{"cell_type":"code","metadata":{"id":"KaUcvPyaLoBa"},"source":["pd.plotting.scatter_matrix(\n","    df.select_dtypes(include='number').iloc[:,-5:-1],\n","    figsize=(12,12)\n",");"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mq_CzQoDM2Yv"},"source":["We can also use a very handy parameter, `c`, which allows us to color the dots in a scatter plot. This is extremely helpful when doing **classification problems**, often you will set the color to the class label."]},{"cell_type":"code","metadata":{"id":"rPfB9HmFMyBa"},"source":["df['Recommended IND'].unique()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LN64E0XUNKNt"},"source":["df.plot(kind='scatter', x='Review Length', y='Polarity', c='Recommended IND', colormap='summer', figsize=(15,7))\n","plt.ylabel('Length')\n","plt.ylabel('Polarity')\n","#plt.savefig('giveaname.png');"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"11HygesnQyB4"},"source":["Recommended reviews tend to be lengthier than those of not recommended reviews."]},{"cell_type":"markdown","metadata":{"id":"u6_j3K3gRXOR"},"source":["#### Boxplot"]},{"cell_type":"code","metadata":{"id":"VVtaTIDiRVkh"},"source":["# Which department is the best rated?\n","y0 = df.loc[df['Department Name'] == 'Tops']['Rating']\n","y1 = df.loc[df['Department Name'] == 'Dresses']['Rating']\n","y2 = df.loc[df['Department Name'] == 'Bottoms']['Rating']\n","y3 = df.loc[df['Department Name'] == 'Intimate']['Rating']\n","y4 = df.loc[df['Department Name'] == 'Jackets']['Rating']\n","y5 = df.loc[df['Department Name'] == 'Trend']['Rating']\n","\n","trace0 = go.Box(\n","    y=y0,\n","    name = 'Tops',\n","    marker = dict(\n","        color = 'rgb(214, 12, 140)',\n","    )\n",")\n","trace1 = go.Box(\n","    y=y1,\n","    name = 'Dresses',\n","    marker = dict(\n","        color = 'rgb(0, 128, 128)',\n","    )\n",")\n","trace2 = go.Box(\n","    y=y2,\n","    name = 'Bottoms',\n","    marker = dict(\n","        color = 'rgb(10, 140, 208)',\n","    )\n",")\n","trace3 = go.Box(\n","    y=y3,\n","    name = 'Intimate',\n","    marker = dict(\n","        color = 'rgb(12, 102, 14)',\n","    )\n",")\n","trace4 = go.Box(\n","    y=y4,\n","    name = 'Jackets',\n","    marker = dict(\n","        color = 'rgb(10, 0, 100)',\n","    )\n",")\n","trace5 = go.Box(\n","    y=y5,\n","    name = 'Trend',\n","    marker = dict(\n","        color = 'rgb(100, 0, 10)',\n","    )\n",")\n","data = [trace0, trace1, trace2, trace3, trace4, trace5]\n","layout = go.Layout(\n","    title = \"Rating Boxplot of Department Name\"\n",")\n","\n","fig = go.Figure(data=data,layout=layout)\n","fig.show(renderer=\"colab\")\n","iplot(fig, filename = \"Rating Boxplot of Department Name\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A8EjA7WMSUvr"},"source":["Except Trend department, all the other departments’ median rating were 5. Overall, the ratings are high and sentiment are positive in this review data set."]},{"cell_type":"markdown","metadata":{"id":"UjreAGznTowg"},"source":["#### Jointplot"]},{"cell_type":"code","metadata":{"id":"3cB2KD3-2dxK"},"source":["trace1 = go.Scatter(\n","    x=df['Age'], y=df['Polarity'], mode='markers', name='points',\n","    marker=dict(color='rgb(102,0,0)', size=2, opacity=0.4)\n",")\n","trace2 = go.Histogram2dContour(\n","    x=df['Age'], y=df['Polarity'], name='density', ncontours=20,\n","    colorscale='Hot', reversescale=True, showscale=False\n",")\n","trace3 = go.Histogram(\n","    x=df['Age'], name='Age density',\n","    marker=dict(color='rgb(102,0,0)'),\n","    yaxis='y2'\n",")\n","trace4 = go.Histogram(\n","    y=df['Polarity'], name='Sentiment Polarity density', marker=dict(color='rgb(102,0,0)'),\n","    xaxis='x2'\n",")\n","data = [trace1, trace2, trace3, trace4]\n","\n","layout = go.Layout(\n","    showlegend=False,\n","    autosize=False,\n","    width=1200,\n","    height=800,\n","    xaxis=dict(\n","        domain=[0, 0.85],\n","        showgrid=False,\n","        zeroline=False\n","    ),\n","    yaxis=dict(\n","        domain=[0, 0.85],\n","        showgrid=False,\n","        zeroline=False\n","    ),\n","    margin=dict(\n","        t=50\n","    ),\n","    hovermode='closest',\n","    bargap=0,\n","    xaxis2=dict(\n","        domain=[0.85, 1],\n","        showgrid=False,\n","        zeroline=False\n","    ),\n","    yaxis2=dict(\n","        domain=[0.85, 1],\n","        showgrid=False,\n","        zeroline=False\n","    )\n",")\n","\n","fig = go.Figure(data=data, layout=layout)\n","iplot(fig, filename='2dhistogram-2d-density-plot-subplots')\n","fig.show(renderer=\"colab\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UKCUJ3Hg2dxK"},"source":["There were few people are very positive or very negative. People who give neutral to positive reviews are more likely to be in their 30s. Probably people at these age are likely to be more active."]},{"cell_type":"code","metadata":{"id":"a_zeFP3PyFHm"},"source":["df.info()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1CkN3aZszmsf"},"source":["#### Correlation matrix\n","Compute pairwise correlation of columns, excluding NA/null values.\n","\n","Parameters\n","method {‘pearson’, ‘kendall’, ‘spearman’} or callable\n","Method of correlation:\n","\n","pearson : standard correlation coefficient\n","\n","kendall : Kendall Tau correlation coefficient\n","\n","spearman : Spearman rank correlation\n","\n","callable: callable with input two 1d ndarrays\n","and returning a float. Note that the returned matrix from corr will have 1 along the diagonals and will be symmetric regardless of the callable’s behavior.\n","\n","min_periodsint, optional\n","Minimum number of observations required per pair of columns to have a valid result. Currently only available for Pearson and Spearman correlation."]},{"cell_type":"code","metadata":{"id":"0pxDW-ddx1hW"},"source":["correlation = df[['Rating','Polarity', 'Review Length', 'Num Tokens']].corr()\n","mask = np.zeros_like(correlation, dtype=np.bool)\n","mask[np.triu_indices_from(mask)] = True\n","plt.figure(figsize=(12,10))\n","plt.xticks(fontsize=20)\n","plt.yticks(fontsize=20)\n","sns.heatmap(correlation, cmap='coolwarm', annot=True, annot_kws={\"size\": 20}, linewidths=10, vmin=-1.5, mask=mask)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oW3lwAiRVgAo"},"source":["### N-gramming\n","\n","N-grams are used to describe the number of words used as observation points, e.g., unigram means singly-worded, bigram means 2-worded phrase, and trigram means 3-worded phrase. In order to do this, we use scikit-learn’s CountVectorizer function."]},{"cell_type":"markdown","metadata":{"id":"6QtxQFbw2dxM"},"source":["#### Unigrams"]},{"cell_type":"code","metadata":{"id":"gCEN6U1U2dxM"},"source":["def get_top_n_words(corpus, n=None):\n","    vec = CountVectorizer().fit(corpus)\n","    bag_of_words = vec.transform(corpus)\n","    sum_words = bag_of_words.sum(axis=0) \n","    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n","    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n","    return words_freq[:n]\n","\n","common_words = get_top_n_words(df['Review Text'], 20)\n","\n","unigrams_w_stops = pd.DataFrame(common_words, columns = ['word' , 'count'])\n","unigrams_w_stops"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ePgvh932dxM"},"source":["unigrams_w_stops.plot(kind='barh', x='word', color='cadetblue', width=0.5, figsize=(5,6))\n","plt.xlabel('count')\n","plt.ylabel('word')\n","plt.title('Unigrams with stopwords')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"WaLMmpZ32dxM"},"source":["# Unigrams after stopword removal\n","def get_top_n_words(corpus, n=None):\n","    vec = CountVectorizer(stop_words = 'english').fit(corpus)\n","    bag_of_words = vec.transform(corpus)\n","    sum_words = bag_of_words.sum(axis=0) \n","    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n","    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n","    return words_freq[:n]\n","common_words = get_top_n_words(df['Review Text'], 20)\n","unigrams = pd.DataFrame(common_words, columns = ['word' , 'count'])\n","unigrams"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e9JlUBDqj5kb"},"source":["unigrams.plot(kind='barh', x='word', color='cadetblue', width=0.5, figsize=(5,6))\n","plt.xlabel('count')\n","plt.ylabel('word')\n","plt.title('Unigrams w/o stopwords')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cerQ_TxD2dxM"},"source":["#### Bigrams"]},{"cell_type":"code","metadata":{"id":"xv_Iw_032dxN"},"source":["def get_top_n_bigram(corpus, n=None):\n","    vec = CountVectorizer(ngram_range=(2, 2), stop_words='english').fit(corpus)\n","    bag_of_words = vec.transform(corpus)\n","    sum_words = bag_of_words.sum(axis=0) \n","    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n","    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n","    return words_freq[:n]\n","common_words = get_top_n_bigram(df['Review Text'], 20)\n","bigrams = pd.DataFrame(common_words, columns = ['word' , 'count'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_GhNr9Jv2dxN"},"source":["bigrams.plot(kind='barh', x='word', color='cadetblue', width=0.5, figsize=(5,6))\n","plt.xlabel('count')\n","plt.ylabel('word')\n","plt.title('Bigrams w/o stopwords')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BteTcv_qQpXX"},"source":["#### Trigrams"]},{"cell_type":"code","metadata":{"id":"yJi-wnLZ2dxN"},"source":["def get_top_n_trigram(corpus, n=None):\n","    vec = CountVectorizer(ngram_range=(3, 3), stop_words='english').fit(corpus)\n","    bag_of_words = vec.transform(corpus)\n","    sum_words = bag_of_words.sum(axis=0) \n","    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n","    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n","    return words_freq[:n]\n","common_words = get_top_n_trigram(df['Review Text'], 20)\n","trigrams = pd.DataFrame(common_words, columns = ['word' , 'count'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FEd4C5xVkkf5"},"source":["trigrams.plot(kind='barh', x='word', color='cadetblue', width=0.5, figsize=(5,6))\n","plt.xlabel('count')\n","plt.ylabel('word')\n","plt.title('Trigrams w/o stopwords')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dxuqKATsvDxr"},"source":["We will talk about n-gram more when we learn about vector representations and classification algorithms. For now, just remember that ngrams can carry special meaning. For instance, data & science might add up closely to data science. However, honeymoon has nothing to do with honey or moon."]}]}